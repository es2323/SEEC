import React, { useState, useRef } from "react";
import { View, Text, Button, StyleSheet, ScrollView, TextInput, TouchableOpacity, Alert } from "react-native"; // Added Alert
import * as Location from "expo-location";
import * as Speech from "expo-speech";
import { Audio } from "expo-av"; // Import Audio from expo-av
import MapView, { Marker } from 'react-native-maps'; // Assuming you have these imports for the MapView


// Fetch bus journey using Google Directions API (transit mode, bus only)
const getBusJourney = async (origin, destination) => {
Â  const apiKey = "AIzaSyArCo5izEub-54JZjKqsLW-qQTwWbkhiJo";
Â  const url = `https://maps.googleapis.com/maps/api/directions/json?origin=${encodeURIComponent(
Â  Â  origin
Â  )}&destination=${encodeURIComponent(
Â  Â  destination
Â  )}&mode=transit&transit_mode=bus&key=${apiKey}`;
Â  const response = await fetch(url);
Â  const data = await response.json();
Â  return data;
};

// Read aloud the journey steps
const speakJourney = (route) => {
Â  let text = "";
Â  route.legs[0].steps.forEach(step => {
Â  Â  if (step.travel_mode === "TRANSIT" && step.transit_details) {
Â  Â  Â  const td = step.transit_details;
Â  Â  Â  text += `Take bus ${td.line.short_name} from ${td.departure_stop.name} at ${td.departure_time.text}. Get off at ${td.arrival_stop.name} at ${td.arrival_time.text}. `;
Â  Â  } else {
Â  Â  Â  text += step.html_instructions.replace(/<[^>]+>/g, "") + ` (${step.distance.text}). `;
Â  Â  }
Â  });
Â  text += `Arrival time: ${route.legs[0].arrival_time ? route.legs[0].arrival_time.text : "N/A"}.`;
Â  Speech.speak(text);
};

// Haversine formula for distance between two lat/lon points (in meters)
const getDistance = (lat1, lon1, lat2, lon2) => {
Â  function toRad(x) { return x * Math.PI / 180; }
Â  const R = 6371e3; // meters
Â  const dLat = toRad(lat2 - lat1);
Â  const dLon = toRad(lon2 - lon1);
Â  const a = Math.sin(dLat/2) * Math.sin(dLat/2) +
Â  Â  Math.cos(toRad(lat1)) * Math.cos(toRad(lat2)) *
Â  Â  Math.sin(dLon/2) * Math.sin(dLon/2);
Â  const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));
Â  return R * c;
};

const FindBusScreen = () => {
Â  const [start, setStart] = useState("");
Â  const [destination, setDestination] = useState("");
Â  const [journeys, setJourneys] = useState([]);
Â  const [error, setError] = useState("");
Â  const [loading, setLoading] = useState(false);
Â  const [navigating, setNavigating] = useState(false);
Â  const [currentStep, setCurrentStep] = useState(0);
Â  const watchId = useRef(null);

  // --- New State for Speech-to-Text ---
  const [isRecording, setIsRecording] = useState(false);
  const [recordingFor, setRecordingFor] = useState(null); // 'start' or 'destination'
  const recording = useRef(null); // useRef to hold the Audio.Recording object
  const [uploading, setUploading] = useState(false);
  const [transcribing, setTranscribing] = useState(false); // New state for transcription status
  const [transcriptionProgress, setTranscriptionProgress] = useState(0); // For future use if backend sends progress

  // --- New Speech-to-Text Functions ---
  const startRecording = async (forField) => {
    try {
      setRecordingFor(forField);
      setIsRecording(true);
      setUploading(false); // Reset upload status
      setTranscribing(false); // Reset transcribing status
      setError(""); // Clear any previous errors

      console.log('Requesting audio recording permissions');
      const { granted } = await Audio.requestPermissionsAsync();
      if (!granted) {
        Alert.alert('Permission Denied', 'Permission to record audio was denied!');
        setIsRecording(false);
        setRecordingFor(null);
        return;
      }
      console.log('Setting up audio recorder');
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true, // Allows other audio to duck when recording starts (Android)
        interruptionModeAndroid: Audio.INTERRUPTION_MODE_ANDROID_DO_NOT_MIX, // Recording takes precedence
        staysActiveInBackground: false, // Don't keep active in background for recording
        interruptionModeIOS: Audio.INTERRUPTION_MODE_IOS_MIX_WITH_OTHERS, // Recording allows other audio to mix (iOS)
      });
      
      const newRecording = new Audio.Recording();
      await newRecording.prepareToRecordAsync(Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY);
      recording.current = newRecording; // Store the recording object in ref
      await recording.current.startAsync();
      
      console.log('Started recording!');
    } catch (err) {
      console.error('Failed to start recording', err);
      Alert.alert('Recording Error', 'Failed to start recording: ' + err.message);
      setIsRecording(false);
      setRecordingFor(null);
    }
  };

  const stopRecording = async () => {
    try {
      setIsRecording(false); // Update UI immediately
      if (!recording.current) {
        console.warn('No recording object to stop.');
        setRecordingFor(null);
        return;
      }

      await recording.current.stopAndUnloadAsync();
      // Reset audio mode to prevent interfering with other app sounds after recording
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: false, // Turn off recording capabilities
        playsInSilentModeIOS: true, // Allow background playback
        shouldDuckAndroid: true,
        interruptionModeAndroid: Audio.INTERRUPTION_MODE_ANDROID_DO_NOT_MIX,
        staysActiveInBackground: false,
        interruptionModeIOS: Audio.INTERRUPTION_MODE_IOS_MIX_WITH_OTHERS,
      });

      const uri = recording.current.getURI();
      console.log('Recording stopped and stored at', uri);
      
      recording.current = null; // Clear the ref
      
      await uploadAndTranscribe(uri); // Call function to upload and transcribe
      setRecordingFor(null); // Clear which field was being recorded for
    } catch (err) {
      console.error('Failed to stop recording', err);
      Alert.alert('Recording Error', 'Failed to stop recording: ' + err.message);
      setRecordingFor(null);
    }
  };

  const uploadAndTranscribe = async (fileUri) => {
    setUploading(true);
    setTranscribing(true);
    setError(""); // Clear previous errors

    const formData = new FormData();
    formData.append('audio_file', {
      uri: fileUri,
      name: `audio_${Date.now()}.m4a`, // Expo AV often saves as .m4a or .caf on iOS, .aac on Android
      type: 'audio/m4a', // Defaulting to m4a, adjust if you confirm a different format
    });

    try {
      // IMPORTANT: Replace with your actual backend URL
      const response = await fetch('http://localhost:5000/api/transcribe', {
        method: 'POST',
        body: formData,
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      });

      const data = await response.json();
      setUploading(false);
      setTranscribing(false);

      if (response.ok && data?.transcription) {
        console.log('Transcription successful:', data.transcription);
        if (recordingFor === 'start') {
          setStart(data.transcription);
        } else if (recordingFor === 'destination') {
          setDestination(data.transcription);
        }
        Alert.alert('Transcription Success', `Recognized: "${data.transcription}"`);
      } else {
        const errorMessage = data?.error || 'Unknown transcription error';
        console.error('Transcription failed:', errorMessage);
        setError(`Transcription failed: ${errorMessage}`);
        Alert.alert('Transcription Failed', errorMessage);
      }
    } catch (error) {
      setUploading(false);
      setTranscribing(false);
      console.error('Error sending audio to backend:', error);
      setError('Failed to send audio for transcription. Check backend server.');
      Alert.alert('Network Error', 'Failed to connect to transcription service. Is your backend running?');
    }
  };


Â  // All your existing functions remain exactly the same
Â  const handleFindBuses = async () => {
Â  Â  setError("");
Â  Â  setJourneys([]);
Â  Â  setLoading(true);
Â  Â  setNavigating(false);
Â  Â  setCurrentStep(0);
Â  Â  if (watchId.current) {
Â  Â  Â  watchId.current.remove();
Â  Â  Â  watchId.current = null;
Â  Â  }
Â  Â  try {
Â  Â  Â  const data = await getBusJourney(start, destination);
Â  Â  Â  setLoading(false);
Â  Â  Â  if (data.status !== "OK" || !data.routes.length) {
Â  Â  Â  Â  setError("No bus journeys found.");
Â  Â  Â  Â  return;
Â  Â  Â  }
Â  Â  Â  setJourneys(data.routes);
Â  Â  } catch (err) {
Â  Â  Â  setLoading(false);
Â  Â  Â  setError("Could not find a bus journey.");
Â  Â  }
Â  };

Â  const getInitialRegion = (route) => {
Â  Â  if (!route || !route.legs || !route.legs[0]) return null;
Â  Â  const startLoc = route.legs[0].start_location;
Â  Â  return {
Â  Â  Â  latitude: startLoc.lat,
Â  Â  Â  longitude: startLoc.lng,
Â  Â  Â  latitudeDelta: 0.05,
Â  Â  Â  longitudeDelta: 0.05,
Â  Â  };
Â  };

Â  const startJourney = async (route) => {
Â  Â  setNavigating(true);
Â  Â  setCurrentStep(0);
Â  Â  let { status } = await Location.requestForegroundPermissionsAsync();
Â  Â  if (status !== "granted") {
Â  Â  Â  setError("Location permission was denied.");
Â  Â  Â  setNavigating(false);
Â  Â  Â  return;
Â  Â  }
Â  Â  const steps = route.legs[0].steps;
Â  Â  watchId.current = await Location.watchPositionAsync(
Â  Â  Â  { accuracy: Location.Accuracy.High, distanceInterval: 10 },
Â  Â  Â  (loc) => {
Â  Â  Â  Â  if (!navigating) return;
Â  Â  Â  Â  if (currentStep < steps.length) {
Â  Â  Â  Â  Â  const step = steps[currentStep];
Â  Â  Â  Â  Â  const { lat, lng } = step.start_location;
Â  Â  Â  Â  Â  const distance = getDistance(
Â  Â  Â  Â  Â  Â  loc.coords.latitude,
Â  Â  Â  Â  Â  Â  loc.coords.longitude,
Â  Â  Â  Â  Â  Â  lat,
Â  Â  Â  Â  Â  Â  lng
Â  Â  Â  Â  Â  );
Â  Â  Â  Â  Â  if (distance < 40) {
Â  Â  Â  Â  Â  Â  let instruction = "";
Â  Â  Â  Â  Â  Â  if (step.travel_mode === "TRANSIT" && step.transit_details) {
Â  Â  Â  Â  Â  Â  Â  const td = step.transit_details;
Â  Â  Â  Â  Â  Â  Â  instruction = `Take bus ${td.line.short_name} from ${td.departure_stop.name} at ${td.departure_time.text}. Get off at ${td.arrival_stop.name} at ${td.arrival_time.text}.`;
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  instruction = step.html_instructions.replace(/<[^>]+>/g, "") + ` (${step.distance.text})`;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Speech.speak(instruction);
Â  Â  Â  Â  Â  Â  setCurrentStep((prev) => prev + 1);
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Speech.speak("You have arrived at your destination.");
Â  Â  Â  Â  Â  stopJourney();
Â  Â  Â  Â  }
Â  Â  Â  }
Â  Â  );
Â  };

Â  const stopJourney = () => {
Â  Â  setNavigating(false);
Â  Â  setCurrentStep(0);
Â  Â  if (watchId.current) {
Â  Â  Â  watchId.current.remove();
Â  Â  Â  watchId.current = null;
Â  Â  }
Â  Â  Speech.speak("Journey navigation stopped.");
Â  };

Â  return (
Â  Â  <ScrollView contentContainerStyle={{ padding: 20 }}>
Â  Â  Â  <Text style={styles.header} accessibilityRole="header">Find Bus Journeys</Text>
Â  Â  Â Â 
Â  Â  Â  <View style={styles.inputContainer}>
Â  Â  Â  Â  <TextInput
Â  Â  Â  Â  Â  style={styles.input}
Â  Â  Â  Â  Â  placeholder="Start location (address or postcode)"
Â  Â  Â  Â  Â  value={start}
Â  Â  Â  Â  Â  onChangeText={setStart}
Â  Â  Â  Â  Â  accessibilityLabel="Enter your start location"
Â  Â  Â  Â  Â  accessibilityRole="search"
Â  Â  Â  Â  />
Â  Â  Â  Â  <TouchableOpacityÂ 
Â  Â  Â  Â  Â  style={[styles.voiceButton, isRecording && recordingFor === 'start' && styles.voiceButtonActive]}
Â  Â  Â  Â  Â  onPressIn={() => startRecording('start')}
Â  Â  Â  Â  Â  onPressOut={stopRecording}
Â  Â  Â  Â  Â  accessibilityLabel="Press and hold to speak start location"
Â  Â  Â  Â  >
Â  Â  Â  Â  Â  <Text style={styles.voiceButtonText}>ðŸŽ¤</Text>
Â  Â  Â  Â  </TouchableOpacity>
Â  Â  Â  </View>
Â  Â  Â Â 
Â  Â  Â  <View style={styles.inputContainer}>
Â  Â  Â  Â  <TextInput
Â  Â  Â  Â  Â  style={styles.input}
Â  Â  Â  Â  Â  placeholder="Destination (address or postcode)"
Â  Â  Â  Â  Â  value={destination}
Â  Â  Â  Â  Â  onChangeText={setDestination}
Â  Â  Â  Â  Â  accessibilityLabel="Enter your destination"
Â  Â  Â  Â  Â  accessibilityRole="search"
Â  Â  Â  Â  />
Â  Â  Â  Â  <TouchableOpacityÂ 
Â  Â  Â  Â  Â  style={[styles.voiceButton, isRecording && recordingFor === 'destination' && styles.voiceButtonActive]}
Â  Â  Â  Â  Â  onPressIn={() => startRecording('destination')}
Â  Â  Â  Â  Â  onPressOut={stopRecording}
Â  Â  Â  Â  Â  accessibilityLabel="Press and hold to speak destination"
Â  Â  Â  Â  >
Â  Â  Â  Â  Â  <Text style={styles.voiceButtonText}>ðŸŽ¤</Text>
Â  Â  Â  Â  </TouchableOpacity>
Â  Â  Â  </View>
Â  Â  Â Â 
Â  Â  Â  <Button
Â  Â  Â  Â  title="Find Buses"
Â  Â  Â  Â  onPress={handleFindBuses}
Â  Â  Â  Â  accessibilityLabel="Find bus journeys"
Â  Â  Â  Â  accessibilityRole="button"
Â  Â  Â  />

      {/* New status indicators for upload and transcription */}
      {uploading && <Text style={styles.statusText}>Uploading audio...</Text>}
      {transcribing && <Text style={styles.statusText}>Transcribing with AssemblyAI...</Text>}
      
Â  Â  Â  {loading && <Text style={styles.statusText}>Loading bus journeys...</Text>}
Â  Â  Â  {error ? <Text style={styles.errorText}>{error}</Text> : null}

Â  Â  Â  {journeys.length > 0 && (
Â  Â  Â  Â  <View style={{ height: 300, marginVertical: 20 }}>
Â  Â  Â  Â  Â  <MapView
Â  Â  Â  Â  Â  Â  style={{ flex: 1 }}
Â  Â  Â  Â  Â  Â  provider="google"
Â  Â  Â  Â  Â  Â  initialRegion={getInitialRegion(journeys[0])}
Â  Â  Â  Â  Â  Â  accessibilityLabel="Map showing the start and destination of the journey"
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <Marker
Â  Â  Â  Â  Â  Â  Â  coordinate={{
Â  Â  Â  Â  Â  Â  Â  Â  latitude: journeys[0].legs[0].start_location.lat,
Â  Â  Â  Â  Â  Â  Â  Â  longitude: journeys[0].legs[0].start_location.lng,
Â  Â  Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  Â  Â  Â  title="Start"
Â  Â  Â  Â  Â  Â  Â  color="blue"
Â  Â  Â  Â  Â  Â  Â  accessibilityLabel="Journey start location"
Â  Â  Â  Â  Â  Â  />
Â  Â  Â  Â  Â  Â  <Marker
Â  Â  Â  Â  Â  Â  Â  coordinate={{
Â  Â  Â  Â  Â  Â  Â  Â  latitude: journeys[0].legs[0].end_location.lat,
Â  Â  Â  Â  Â  Â  Â  Â  longitude: journeys[0].legs[0].end_location.lng,
Â  Â  Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  Â  Â  Â  title="Destination"
Â  Â  Â  Â  Â  Â  Â  color="red"
Â  Â  Â  Â  Â  Â  Â  accessibilityLabel="Journey destination"
Â  Â  Â  Â  Â  Â  />
Â  Â  Â  Â  Â  </MapView>
Â  Â  Â  Â  </View>
Â  Â  Â  )}

Â  Â  Â  {journeys.length > 0 && (
Â  Â  Â  Â  <Button
Â  Â  Â  Â  Â  title={navigating ? "Stop Journey" : "Start Journey"}
Â  Â  Â  Â  Â  onPress={() =>
Â  Â  Â  Â  Â  Â  navigating ? stopJourney() : startJourney(journeys[0])
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  color={navigating ? "#d9534f" : "#007AFF"}
Â  Â  Â  Â  Â  accessibilityLabel={navigating ? "Stop journey navigation" : "Start journey navigation with audio"}
Â  Â  Â  Â  />
Â  Â  Â  )}

Â  Â  Â  {journeys.length > 0 &&
Â  Â  Â  Â  journeys.map((route, idx) => (
Â  Â  Â  Â  Â  <View
Â  Â  Â  Â  Â  Â  key={idx}
Â  Â  Â  Â  Â  Â  style={styles.journeyBox}
Â  Â  Â  Â  Â  Â  accessible
Â  Â  Â  Â  Â  Â  accessibilityLabel={`Journey option ${idx + 1}`}
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <Text style={styles.subheader}>Journey {idx + 1}:</Text>
Â  Â  Â  Â  Â  Â  <Button
Â  Â  Â  Â  Â  Â  Â  title="Read Aloud"
Â  Â  Â  Â  Â  Â  Â  onPress={() => speakJourney(route)}
Â  Â  Â  Â  Â  Â  Â  accessibilityLabel="Read this journey aloud"
Â  Â  Â  Â  Â  Â  Â  accessibilityRole="button"
Â  Â  Â  Â  Â  Â  Â  color="#228B22"
Â  Â  Â  Â  Â  Â  />
Â  Â  Â  Â  Â  Â  {route.legs[0].steps.map((step, sidx) => {
Â  Â  Â  Â  Â  Â  Â  if (step.travel_mode === "TRANSIT" && step.transit_details) {
Â  Â  Â  Â  Â  Â  Â  Â  const td = step.transit_details;
Â  Â  Â  Â  Â  Â  Â  Â  return (
Â  Â  Â  Â  Â  Â  Â  Â  Â  <Text
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key={sidx}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  style={styles.stepText}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  accessibilityLabel={`Take bus ${td.line.short_name} from ${td.departure_stop.name} at ${td.departure_time.text}. Get off at ${td.arrival_stop.name} at ${td.arrival_time.text}.`}
Â  Â  Â  Â  Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ðŸšŒ Take bus {td.line.short_name} from "{td.departure_stop.name}" at {td.departure_time.text}.{"\n"}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Get off at "{td.arrival_stop.name}" at {td.arrival_time.text}.
Â  Â  Â  Â  Â  Â  Â  Â  Â  </Text>
Â  Â  Â  Â  Â  Â  Â  Â  );
Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  return (
Â  Â  Â  Â  Â  Â  Â  Â  Â  <Text
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key={sidx}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  style={styles.stepText}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  accessibilityLabel={step.html_instructions.replace(/<[^>]+>/g, "")}
Â  Â  Â  Â  Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ðŸš¶ {step.html_instructions.replace(/<[^>]+>/g, "")} ({step.distance.text})
Â  Â  Â  Â  Â  Â  Â  Â  Â  </Text>
Â  Â  Â  Â  Â  Â  Â  Â  );
Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  })}
Â  Â  Â  Â  Â  Â  <Text style={styles.arrivalText}>
Â  Â  Â  Â  Â  Â  Â  Arrival time: {route.legs[0].arrival_time ? route.legs[0].arrival_time.text : "N/A"}
Â  Â  Â  Â  Â  Â  </Text>
Â  Â  Â  Â  Â  </View>
Â  Â  Â  Â  ))}
Â  Â  </ScrollView>
Â  );
};

const styles = StyleSheet.create({
Â  header: { fontWeight: "bold", fontSize: 26, marginBottom: 14, color: "#222" },
Â  subheader: { fontWeight: "bold", marginTop: 15, fontSize: 20, color: "#222" },
Â  inputContainer: { // Added style for the new View surrounding TextInput and TouchableOpacity
Â  Â  flexDirection: 'row',
Â  Â  alignItems: 'center',
Â  Â  marginVertical: 10,
Â  },
Â  input: {Â 
Â  Â  flex: 1, // Added flex to make TextInput take available space
Â  Â  borderWidth: 2,Â 
Â  Â  borderColor: "#222",Â 
Â  Â  padding: 12,Â 
Â  Â  borderRadius: 7,Â 
Â  Â  fontSize: 18,Â 
Â  Â  backgroundColor: "#fff"Â 
Â  },
Â  journeyBox: { backgroundColor: "#fffbe6", padding: 14, marginVertical: 14, borderRadius: 10, borderColor: "#222", borderWidth: 1 },
Â  stepText: { fontSize: 18, marginVertical: 4, color: "#222" },
Â  arrivalText: { fontWeight: "bold", marginTop: 10, fontSize: 18, color: "#222" },
Â  statusText: { fontSize: 18, color: "#222", marginVertical: 10 },
Â  errorText: { color: "#b00020", fontSize: 18, marginVertical: 10 },
  voiceButton: { // New style for the microphone button
    padding: 12,
    marginLeft: 8,
    backgroundColor: '#f0f0f0',
    borderRadius: 20,
    borderWidth: 1,
    borderColor: '#ccc',
  },
  voiceButtonActive: { // Style for when recording is active
    backgroundColor: '#ffcccc', // Light red to indicate active recording
  },
  voiceButtonText: {
    fontSize: 20,
  },
});

export default FindBusScreen;